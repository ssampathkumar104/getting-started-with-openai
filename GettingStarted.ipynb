{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a429e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58c8a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb5b3cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print(requests.get(\"https://api.openai.com\", timeout=10).status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-2025-04-14\", \n",
    "                 temperature=0,     \n",
    "                 timeout=20,\n",
    "                 max_retries=2)\n",
    "# print(llm) //Don't print llm object. It hangs the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a18265fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is Generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f427389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Generative AI** refers to a category of artificial intelligence models and systems designed to create new content, data, or solutions that resemble human-made outputs. Unlike traditional AI, which typically classifies, predicts, or analyzes existing data, generative AI can **generate** new text, images, music, code, videos, and more.\\n\\n### How Does Generative AI Work?\\nGenerative AI models are usually trained on large datasets and learn patterns, structures, and relationships within the data. They use this knowledge to produce new, original content. The most common types of generative AI models include:\\n\\n- **Generative Adversarial Networks (GANs):** Used mainly for generating images and videos.\\n- **Variational Autoencoders (VAEs):** Used for generating new data points similar to the training data.\\n- **Transformer-based models (like GPT, BERT, etc.):** Used for generating human-like text, code, and more.\\n\\n### Examples of Generative AI\\n- **Text:** ChatGPT, which can write essays, answer questions, or generate stories.\\n- **Images:** DALL-E, Midjourney, or Stable Diffusion, which can create realistic or artistic images from text prompts.\\n- **Music:** AI systems that compose original music tracks.\\n- **Code:** AI tools that generate programming code from natural language descriptions.\\n\\n### Applications\\n- Content creation (writing, art, music)\\n- Product design and prototyping\\n- Drug discovery and molecular design\\n- Data augmentation for machine learning\\n- Personalized recommendations and chatbots\\n\\n### Summary\\n**Generative AI** is a powerful technology that enables machines to create new, original content, often indistinguishable from human-made work, by learning from vast amounts of data. Its applications are rapidly expanding across industries, transforming how we create and interact with digital content.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 13, 'total_tokens': 384, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-D2gWG6nmWmNbCYtfMj2Fztt59hRkn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c005a-bb16-7561-afbb-f2db210f102d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 13, 'output_tokens': 371, 'total_tokens': 384, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50ee3ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI Engineer. Provide me answers based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an AI Engineer. Provide me answers based on the question.\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1c15288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**LangChain** is a Python library that helps you build applications using large language models (like ChatGPT) more easily and powerfully.\\n\\n**In simple terms:**\\n- Imagine you want to build a chatbot, a document search tool, or an AI assistant.\\n- LangChain gives you building blocks to connect language models with data sources (like your files, databases, or the internet), and lets you control how the AI thinks and responds.\\n- It helps you chain together different steps (like searching, summarizing, and answering) to create smart, multi-step AI workflows.\\n\\n**Key points:**\\n- Makes it easier to use language models in real-world apps.\\n- Lets you connect AI to your own data.\\n- Helps you design complex AI behaviors by combining simple steps.\\n\\n**Example:**  \\nWith LangChain, you can build an app where a user asks a question, the AI searches your documents for answers, summarizes the findings, and then replies—all in one smooth process.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 197, 'prompt_tokens': 32, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-D2gWSaT7KA9n3eeoNeR8QMfuFoIU7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c005a-e99e-7d10-8273-372c547a0568-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 32, 'output_tokens': 197, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\":\"Explain LangChain in simple terms.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89b0350b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61bc469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LangChain** is a Python library that helps you build applications using large language models (like ChatGPT) more easily and powerfully.\n",
      "\n",
      "**In simple terms:**\n",
      "- Imagine you want to build a chatbot, a document search tool, or an AI assistant.\n",
      "- LangChain gives you building blocks to connect language models with your own data, tools, and workflows.\n",
      "- It helps you chain together different steps (like searching documents, calling APIs, or asking follow-up questions) so the AI can do more complex tasks.\n",
      "\n",
      "**Key points:**\n",
      "- **Connects LLMs to data:** Lets AI read your files, databases, or websites.\n",
      "- **Chains steps:** You can combine multiple actions (e.g., search, summarize, answer) in a sequence.\n",
      "- **Integrates tools:** Easily add things like web search, calculators, or custom functions.\n",
      "\n",
      "**Example:**  \n",
      "With LangChain, you could build an app where a user asks a question, the AI searches your company’s documents, summarizes the answer, and sends it back—all in one smooth process.\n",
      "\n",
      "**Summary:**  \n",
      "LangChain makes it easier to build smart, multi-step AI applications that use language models and your own data or tools.\n"
     ]
    }
   ],
   "source": [
    "#String output parser\n",
    "# from langchain_core.output_parsers import StringOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "response = chain.invoke({\"input\":\"Explain LangChain in simple terms.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d4a81",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
